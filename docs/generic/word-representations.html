<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Word Representations - The Little Book of NLP</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">The Little Book of NLP</li><li class="chapter-item expanded "><a href="../generic/generic.html"><strong aria-hidden="true">1.</strong> Generic</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../generic/word-representations.html" class="active"><strong aria-hidden="true">1.1.</strong> Word Representations</a></li><li class="chapter-item expanded "><a href="../generic/metrics.html"><strong aria-hidden="true">1.2.</strong> Metrics</a></li><li class="chapter-item expanded "><a href="../generic/vector-similarity.html"><strong aria-hidden="true">1.3.</strong> Vector Similarity</a></li></ol></li><li class="chapter-item expanded "><a href="../classical/classical.html"><strong aria-hidden="true">2.</strong> Classical</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../classical/n-grams.html"><strong aria-hidden="true">2.1.</strong> N-Grams</a></li><li class="chapter-item expanded "><a href="../classical/text-processing.html"><strong aria-hidden="true">2.2.</strong> Text Processing</a></li><li class="chapter-item expanded "><a href="../classical/sequence-labelling.html"><strong aria-hidden="true">2.3.</strong> Sequence Labelling</a></li><li class="chapter-item expanded "><a href="../classical/grammars.html"><strong aria-hidden="true">2.4.</strong> Grammars</a></li></ol></li><li class="chapter-item expanded "><a href="../neural/neural.html"><strong aria-hidden="true">3.</strong> Neural</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../neural/rnn.html"><strong aria-hidden="true">3.1.</strong> RNN</a></li><li class="chapter-item expanded "><a href="../neural/transformers.html"><strong aria-hidden="true">3.2.</strong> Transformers</a></li><li class="chapter-item expanded "><a href="../neural/information-extraction.html"><strong aria-hidden="true">3.3.</strong> Information Extraction</a></li><li class="chapter-item expanded "><a href="../neural/machine-translation.html"><strong aria-hidden="true">3.4.</strong> Machine Translation</a></li><li class="chapter-item expanded "><a href="../neural/semantic-role-labelling.html"><strong aria-hidden="true">3.5.</strong> Semantic Role Labelling</a></li><li class="chapter-item expanded "><a href="../neural/word-sense-disambiguation.html"><strong aria-hidden="true">3.6.</strong> Word Sense Disambiguation</a></li><li class="chapter-item expanded "><a href="../neural/question-answering.html"><strong aria-hidden="true">3.7.</strong> Question Answering</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Little Book of NLP</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/jackdarlison/the-little-book-of-nlp" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="word-representations"><a class="header" href="#word-representations">Word Representations</a></h1>
<p>Word representations are methods of creating a numerical representation of a span of text.</p>
<h2 id="feature-sets"><a class="header" href="#feature-sets">Feature Sets</a></h2>
<p>Feature sets are handcrafted lists of features, these features depend on the available information for the task. </p>
<p>For example, common Named Entity Recognition features include:</p>
<ul>
<li>Word shapes</li>
<li>Word features: suffixes, prefixes, capitalisation</li>
<li>POS tags</li>
<li>Word lookups (gazetteers)</li>
</ul>
<p>They are expensive to create as the choice of features are manually chosen. This also makes them difficult to adapt and tune, as it is hard to tell what features are achieving what goals</p>
<h1 id="embeddings"><a class="header" href="#embeddings">Embeddings</a></h1>
<p>Vector embeddings are created automatically, learning representations of text based on a set of training data. </p>
<p>Embeddings represent words as a point in a continuous multi-dimensional space</p>
<h2 id="sparse-embeddings"><a class="header" href="#sparse-embeddings">Sparse Embeddings</a></h2>
<p>Sparse embeddings are called as such as many of the entries in the vector will be zero. </p>
<p>There are two methods of creating sparse embeddings</p>
<h4 id="term-frequency---inverse-document-frequency-tf-idf"><a class="header" href="#term-frequency---inverse-document-frequency-tf-idf">Term Frequency - Inverse Document Frequency (TF-IDF)</a></h4>
<p>TF-IDF uses a term-document matrix, where each cell contains the count of a specific word (rows) in a specific document (columns). </p>
<p>The matrix is weighted by two factors:</p>
<ul>
<li>Term frequency:  \( \text{TF}(t, d) = \log_{10}(\text{count}(t,d)+1) \)</li>
<li>Inverse Document Frequency: \( \text{IDF}(t)=\log_{10}(\frac{N}{\text{count}_{docs}(t)}) \)</li>
</ul>
<p>Which weights each cell by the number of times it appear in the document times the inverse of the number of documents it appears in. Giving the formula for weighting each cell as:</p>
<p>\[ \text{TF-IDF}(t,d)=\text{TF}(t,d) \times \text{IDF}(t) \]</p>
<p>Both factors are used as:</p>
<ul>
<li>Term frequency doesn't discriminate</li>
<li>Inverse document frequency is useless alone, but shows which words are important to certain documents</li>
</ul>
<h4 id="positive-pointwise-mutual-information-ppmi"><a class="header" href="#positive-pointwise-mutual-information-ppmi">Positive Pointwise Mutual Information (PPMI)</a></h4>
<p>PPMI uses a term-term matrix, where each cell counts the co-occurrences of a target word (rows) and a context word (columns). Co-occurrences are defined as the number of times the context word appears within a ±N context window around the target word. </p>
<p>PPMI is a measure of how much more two words co-occur than is expected if they were independent. </p>
<p>It is calculated as:
\[ \text{PPMI}(w, c) = \text{max}( \log_{2} \frac{P(w, c)}{P(w)P(c)}, 0) \]</p>
<p>Only positive values are used as negative values are unreliable unless the corpus is massive. </p>
<p>The probabilities are calculated: (w, c) is the cell count, (w) is the row count, and (c) is the column count, all divided by the total count</p>
<h2 id="dense-embeddings"><a class="header" href="#dense-embeddings">Dense Embeddings</a></h2>
<p>Dense embeddings are much smaller vectors (usually with dimensions in the hundreds), where all values take meaningful real numbers. </p>
<p>Static embeddings learn one fixed embedding for each word.</p>
<p>Word2vec (Skip-gram with negative sampling) is an example algorithm to compute static dense embeddings. In which a self-supervised classifier is trained to classify is two words co-occur, i.e. the context word appears in a ±N window of the target word.  The weights are then used as the embeddings for words.</p>
<p>To train the weights:</p>
<ul>
<li>The classifier initialises two sets of weights randomly for each word, one for its target representation and the other for its context representation. </li>
<li>For all words, use the N context words and sample kN random words using weighted unigram frequency (i.e. counts to the power of \(\alpha\), commonly 0.75) to give more weight to rare words</li>
<li>Adjust the weights to maximise the vector similarity of the context word pairs and minimise the similarity of the negative words</li>
</ul>
<p>As two embeddings are learnt for each word it is common to either add them together or just use the target word embeddings</p>
<p>Other types of static include:</p>
<ul>
<li><em>fasttext</em>: an extension on word2vec using a sub-word model to better handle unknown words and word sparsity</li>
<li>GloVe: captures global corpus statistics from ratios of probabilities in a term-term matrix</li>
</ul>
<p>Contextual embeddings (such as BERT) capture embeddings for each word sense. </p>
<h4 id="benefits-over-sparse-embeddings"><a class="header" href="#benefits-over-sparse-embeddings">Benefits over sparse embeddings</a></h4>
<p>Dense embeddings are better than sparse as:</p>
<ul>
<li>They require less weights due to the lower dimensions, which helps with generalisation and avoiding overfitting</li>
<li>They capture relations between words</li>
</ul>
<h4 id="semantic-properties-of-dense-embeddings"><a class="header" href="#semantic-properties-of-dense-embeddings">Semantic Properties of Dense Embeddings</a></h4>
<p>In word2vec the size of the context window can alter the types of association between vectors:</p>
<ul>
<li>Smaller context windows (±2) show first-order co-occurrence (syntagmatic association). Which means the words are typically near each other. </li>
<li>Larger context windows (±5) show second-order co-occurrence (paradigmatic association). Which means the words share similar neighbours.</li>
</ul>
<p>Embeddings encode properties such as:</p>
<ul>
<li>Relational similarity/meaning: e.g. King - man + women = queen (the parallelogram model)</li>
<li>Implicit corpus bias</li>
</ul>
<p>With multiple corpuses (e.g. historical, cultural, document type, ...) analysing the differences in word embeddings can show the change in meaning and associations words may have</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../generic/generic.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../generic/metrics.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../generic/generic.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../generic/metrics.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>

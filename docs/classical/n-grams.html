<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>N-Grams - The Little Book of NLP</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">The Little Book of NLP</li><li class="chapter-item expanded "><a href="../generic/generic.html"><strong aria-hidden="true">1.</strong> Generic</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../generic/word-representations.html"><strong aria-hidden="true">1.1.</strong> Word Representations</a></li><li class="chapter-item expanded "><a href="../generic/metrics.html"><strong aria-hidden="true">1.2.</strong> Metrics</a></li><li class="chapter-item expanded "><a href="../generic/vector-similarity.html"><strong aria-hidden="true">1.3.</strong> Vector Similarity</a></li></ol></li><li class="chapter-item expanded "><a href="../classical/classical.html"><strong aria-hidden="true">2.</strong> Classical</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../classical/n-grams.html" class="active"><strong aria-hidden="true">2.1.</strong> N-Grams</a></li><li class="chapter-item expanded "><a href="../classical/text-processing.html"><strong aria-hidden="true">2.2.</strong> Text Processing</a></li><li class="chapter-item expanded "><a href="../classical/sequence-labelling.html"><strong aria-hidden="true">2.3.</strong> Sequence Labelling</a></li><li class="chapter-item expanded "><a href="../classical/grammars.html"><strong aria-hidden="true">2.4.</strong> Grammars</a></li></ol></li><li class="chapter-item expanded "><a href="../neural/neural.html"><strong aria-hidden="true">3.</strong> Neural</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../neural/rnn.html"><strong aria-hidden="true">3.1.</strong> RNN</a></li><li class="chapter-item expanded "><a href="../neural/transformers.html"><strong aria-hidden="true">3.2.</strong> Transformers</a></li><li class="chapter-item expanded "><a href="../neural/information-extraction.html"><strong aria-hidden="true">3.3.</strong> Information Extraction</a></li><li class="chapter-item expanded "><a href="../neural/machine-translation.html"><strong aria-hidden="true">3.4.</strong> Machine Translation</a></li><li class="chapter-item expanded "><a href="../neural/semantic-role-labelling.html"><strong aria-hidden="true">3.5.</strong> Semantic Role Labelling</a></li><li class="chapter-item expanded "><a href="../neural/word-sense-disambiguation.html"><strong aria-hidden="true">3.6.</strong> Word Sense Disambiguation</a></li><li class="chapter-item expanded "><a href="../neural/question-answering.html"><strong aria-hidden="true">3.7.</strong> Question Answering</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Little Book of NLP</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/jackdarlison/the-little-book-of-nlp" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="n-grams"><a class="header" href="#n-grams">N-Grams</a></h1>
<p>A language model is one that assigns a probability to each possible next word in a sequence. </p>
<p>The probability of a sequence of words is the joint probability of each word given all previous words.</p>
<p>\[ P(w_{1:n}) = P(w_1)P(w_2 \vert w_1)P(w_3 \vert w_{1:2})...P(w_n \vert w_{1:n-1}) \]</p>
<p>As there is no way to compute the probability of a word given a long sequence of preceding words, n-grams use a generalised form of the Markov assumption (the current state only depends on the previous, i.e. the bigram) where the current state depends on the previous n-1 states. </p>
<p>For a bigram model:</p>
<p>\[ P(w_{1:n}) = P(w_1)P(w_2 \vert w_1) \dots P(w_n \vert w_{n-1}) \]</p>
<p>Where there is a start if sentence marker:</p>
<p>\[ P(w_{1:n}) = P(w_1| \lt s \gt)P(w_2 \vert w_1) \dots P(w_n \vert w_{n-1}) \]</p>
<p>The probability (maximum likelihood estimation, MLE) for an n-gram is given by the count of the n-gram normalised by the count of the preceding (n-1)-gram:</p>
<p>\[ P(w_n | w_{n-N+1:n-1}) = \frac{C(w_{n-N+1:n-1}w_n)}{C(w_{n-N+1:n-1})} \]</p>
<p>Where \( N \) is the size of the n-gram</p>
<p>To evaluate an n-gram model <a href="../generic/metrics.html#Perplexity">perplexity</a> is used.</p>
<h2 id="dealing-with-unknown-words"><a class="header" href="#dealing-with-unknown-words">Dealing with Unknown Words</a></h2>
<p>It is possible that words may appear in the test set that where not in the training set. </p>
<p>One method of dealing with this is to enforce a <em>close vocabulary</em>, where all test words need to be known.</p>
<p>However, in most situations language models need to be able to handle unknown words, also known as <em>out of vocabulary</em> (OOV) words.  To do this a new pseudo-word token &lt;UNK&gt; is added to the vocabulary, making it an <em>open vocabulary</em></p>
<p>There are two common ways to create an open vocabulary:</p>
<ul>
<li>Choose a fixed vocabulary and replace all words in the training set with the &lt;UNK&gt; that do not appear in the fixed vocabulary</li>
<li>Replace all words in the training set that have less than a certain frequency or are not in the most frequent X words with &lt;UNK&gt;</li>
</ul>
<p>This pseudo-word is then estimated like any other word. Unknown words in the test set are then treated as the &lt;UNK&gt; token</p>
<h2 id="dealing-with-sparse-data"><a class="header" href="#dealing-with-sparse-data">Dealing with Sparse Data</a></h2>
<p>Another issue that occurs in n-gram models is the sparsity of n-grams, i.e. known words appearing in a new sequence or context.</p>
<h4 id="laplace-smoothing"><a class="header" href="#laplace-smoothing">Laplace Smoothing</a></h4>
<p>One method of solving this is shifting some of the probability mass from probable words to words that appear less. This is known as <strong>Laplace</strong> smoothing where \( k \) is added to all all word counts, this is commonly known as add-1 or add-\(k\) smoothing. </p>
<p>\[ P_{\text{Laplace}}(w_n \vert w_{n-N+1:n-1}) = \frac{C(w_{n-N+1:n-1}w_n)+k}{C(w_{n-N+1:n-1})+kV} \]</p>
<p>Note: \( kV \) has been added to the denominator to take into account the extra counts across the whole vocabulary</p>
<h4 id="backoff-and-interpolation"><a class="header" href="#backoff-and-interpolation">Backoff and Interpolation</a></h4>
<p>Another method of dealing with sparse n-grams is to take into account the probability of the lower-order n-grams. There are two methods of doing this.</p>
<p><strong>Backoff</strong> is one method, which uses the highest-order n-gram that has been seen.</p>
<p>In order for backoff to give a valid probability distribution, a function \( \alpha \) is used to distribute the mass to the lower-order n-grams. This is known as <strong>Backoff with discounting</strong> or <strong>Katz Backoff</strong></p>
<p><strong>Interpolation</strong> is another method which mixes the probabilities of the n-gram and its lower-order variations. This is done by adding the probability of each n-gram together, each weighted by some factor \( \lambda_i \). The sum of all weights needs to add to 1 to ensure the probability distribution remains valid. </p>
<p>\[ \hat{P}(w_n | w_{n-2:n-1}) = \lambda_1P(w_n) + \lambda_2P(w_n|w_{n-1}) + \lambda_3P(w_n|w_{n-2:n-1}) \]</p>
<p>It is possible to also compute weights depending on the context sequences. </p>
<p>These weights are trained using a held-out corpus, ensuring it does not overfit to the actual training data. </p>
<p>Other forms of dealing with unknown contexts are:</p>
<ul>
<li>Stupid backoff</li>
<li>Kesner-Ney Smoothing</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../classical/classical.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../classical/text-processing.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../classical/classical.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../classical/text-processing.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
